{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kobe Bryant Shot Probability\n",
    "## Kevin Shain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/kshain/Documents/Git')\n",
    "from progressbar import ProgressBar\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "* [Import data](#Import-data)\n",
    "* [Feature engineering](#Feature-engineering)\n",
    "    * [Location to polar coordinates](#Location-to-polar-coordinates)\n",
    "    * [Remaining time](#Remaining-time)\n",
    "    * [Season](#Season)\n",
    "    * [Home or away](#Home-or-away)\n",
    "    * [Dropping uninformative data](#Dropping-uninformative-data)\n",
    "    * [Date to day](#Date-to-day)\n",
    "    * [Categorical data to indicators](#Categorical-data-to-indicators)\n",
    "* [Separating the submission data](#Separating-the-submission-data)\n",
    "* [Log loss function](#Log-loss-function)\n",
    "* [Modeling](#Modeling)\n",
    "    * [Random forest classifier](#Random-forest-classifier)\n",
    "        * [Visualizing the random forest](#Visualizing-the-random-forest)\n",
    "    * [Extra trees classifier](#Extra-trees-classifier)\n",
    "    * [Gradient boosting](#Gradient-boosting)\n",
    "    * [Final model](#Final-model)\n",
    "* [Submission](#Submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename= \"data.csv\"\n",
    "rawdata = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = rawdata #just to keep the raw data in its original form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location to polar coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polar coordinates would seem to make more sense than cartesian since the shooting area is roughly circularly symmetric around the basket. We have treat the case of `loc_x`=0 separately since we would be taking the arctan of infinity. This arctan is well defined to by $\\frac{\\pi}{2}$, but it's better to handle the infinity case symbolically instead of with Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['dist'] = np.sqrt(data['loc_x']**2 + data['loc_y']**2)\n",
    "\n",
    "loc_dist_zero = data['dist'] == 0\n",
    "data['angle'] = np.empty(len(data))\n",
    "data['angle'][~loc_dist_zero] = np.arccos(data['loc_x'][~loc_dist_zero] / data['dist'][~loc_dist_zero])\n",
    "data['angle'][loc_dist_zero] = -np.pi / 2 #angle won't matter if dist=0 anyways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remaining time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two columns that are representing the same thing, time remaining in the game. We just need to fix the units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['remaining_time'] = data['minutes_remaining'] * 60 + data['seconds_remaining']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Season\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The season based on the calendar year when the shots were taken. We want to keep the relative spacing of the years, but absolute doesn't matter. I'll therefore make a column of the year be relative to Kobe's start in the league. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['year'] = data['season'].apply(lambda x: int(x.split('-')[0])-1996)\n",
    "data = data.drop('season',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Home or away"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This information is potentially very important and is encoded in the `matchup` data as the '@' for away games or 'vs.' for home games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d07e23803284>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ishome'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'vs.'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatchup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data['ishome'] = ['vs.' in data.matchup[t] for t in range(len(data))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping uninformative data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columns now have uninformative data and will not be needed in the model. Some of these are uninformative since they always take on the same value, like `team_name`. Others have information that is entirely encoded in other variables, like `game_id`. We must be careful not to eliminate data too soon, but one can proceed without dropping these columns and experiment to see that they do not have predictive value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drops = ['shot_id', 'team_id', 'team_name', 'shot_zone_area', 'shot_zone_range', 'shot_zone_basic', \\\n",
    "         'matchup', 'seconds_remaining', 'minutes_remaining', \\\n",
    "         'shot_distance', 'loc_x', 'loc_y', 'game_event_id', 'game_id']\n",
    "for drop in drops:\n",
    "    data = data.drop(drop, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date to day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a bit hard to use the date as an input to any sort of classifier when it is composed of a year, month, and day. Therefore, I strip the time object to yield a day in the season. This is useful in that one anticipates that the idea of when one month ends and another begins is somewhat arbitrary, but there is likely to be value in data about when during the season a game was played."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['day_In_Season'] = data.game_date.apply(lambda x: time.strptime(x, \"%Y-%m-%d\").tm_yday-300)\n",
    "data['day_In_Season'] = data['day_In_Season'].apply(lambda x: x if x >= 0 else x+365)\n",
    "data = data.drop('game_date',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical data to indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I want to make a non-dummy dataframe since that is easier to work with in non Random forest contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_preDummies = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for each categorical variable in the data, I use the `pandas.get_dummies` function to make indicator variable for each category and afterward, I drop the categorical column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_vars = ['action_type', 'combined_shot_type', 'shot_type', 'opponent', 'period']\n",
    "for var in categorical_vars:\n",
    "    data = pd.concat([data, pd.get_dummies(data[var], prefix=var)], 1)\n",
    "    data = data.drop(var, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating the submission data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to make a submission dataframe that contains only the shots that I am tasked with predicting. These are marked `null` in the dataset so I just find those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = data[pd.isnull(data['shot_made_flag'])]\n",
    "submission = submission.drop('shot_made_flag', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, I need separate the rest of the data, used for training, into features and targets, also known as x and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_all = data[pd.notnull(data['shot_made_flag'])]\n",
    "train_x = train_all.drop('shot_made_flag', 1)\n",
    "train_y = train_all.shot_made_flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log loss function is used by Kaggle to grade your predictions. It conveniently quantifies how confidently right or wrong the prediction was, since the goal is to predict a shot percentage, but each shot is either a make (1) or a miss (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logloss(actual, pred):\n",
    "    epsilon = 1e-15\n",
    "    pred = scipy.maximum(epsilon, pred) #buffer from 0 so that the log loss isn't infinite\n",
    "    pred = scipy.minimum(1-epsilon, pred)\n",
    "    logl = sum(actual*scipy.log(pred) + scipy.subtract(1,actual)*scipy.log(scipy.subtract(1,pred)))\n",
    "    logl = logl * -1.0/len(actual)\n",
    "    return logl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest classifier is a great out-of-the-box classifier for this type of data. The random forest is built on decision trees where each node uses only one feature, thus feature normalization is not needed like in an SVM. The real trick to using random forests is choosing the right features to include, and to a lesser extent, selecting the number of trees and maximum depth. The following loops try a variety of number of trees and depths and uses k-fold cross-validation to show the optimal parameters. It turns out that these parameter values are not nearly as important as the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Finding best n_estimators for RandomForestClassifier...')\n",
    "min_score = 100000\n",
    "best_n = 0\n",
    "scores_n = []\n",
    "range_n = np.linspace(100,800,num=8).astype(int)\n",
    "for n in range_n:\n",
    "    print(\"the number of trees : {0}\".format(n))\n",
    "    t1 = time.time()\n",
    "    \n",
    "    rfc_score = 0.\n",
    "    rfc = RandomForestClassifier(n_estimators=n)\n",
    "    for train_k, test_k in KFold(len(train_x), n_folds=10, shuffle=True):\n",
    "        rfc.fit(train_x.iloc[train_k], train_y.iloc[train_k])\n",
    "        #rfc_score += rfc.score(train.iloc[test_k], train_y.iloc[test_k])/10\n",
    "        pred = rfc.predict_proba(train_x.iloc[test_k])\n",
    "        rfc_score += logloss(train_y.iloc[test_k], pred[:,1]) / 10\n",
    "    scores_n.append(rfc_score)\n",
    "    if rfc_score < min_score:\n",
    "        min_score = rfc_score\n",
    "        best_n = n\n",
    "        \n",
    "    t2 = time.time()\n",
    "    print('Done processing {0} trees ({1:.3f}sec)'.format(n, t2-t1))\n",
    "print(best_n, min_score)\n",
    "\n",
    "\n",
    "# find best max_depth for RandomForestClassifier\n",
    "print('Finding best max_depth for RandomForestClassifier...')\n",
    "min_score = 100000\n",
    "best_m = 0\n",
    "scores_m = []\n",
    "range_m = np.linspace(5,40,num=8).astype(int)\n",
    "for m in range_m:\n",
    "    print(\"the max depth : {0}\".format(m))\n",
    "    t1 = time.time()\n",
    "    \n",
    "    rfc_score = 0.\n",
    "    rfc = RandomForestClassifier(max_depth=m, n_estimators=best_n)\n",
    "    for train_k, test_k in KFold(len(train_x), n_folds=10, shuffle=True):\n",
    "        rfc.fit(train_x.iloc[train_k], train_y.iloc[train_k])\n",
    "        #rfc_score += rfc.score(train.iloc[test_k], train_y.iloc[test_k])/10\n",
    "        pred = rfc.predict_proba(train_x.iloc[test_k])\n",
    "        rfc_score += logloss(train_y.iloc[test_k], pred[:,1]) / 10\n",
    "    scores_m.append(rfc_score)\n",
    "    if rfc_score < min_score:\n",
    "        min_score = rfc_score\n",
    "        best_m = m\n",
    "    \n",
    "    t2 = time.time()\n",
    "    print('Done processing {0} trees ({1:.3f}sec)'.format(m, t2-t1))\n",
    "print(best_m, min_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just some simple plots can show how the log loss score can be affected by the parameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(range_n, scores_n)\n",
    "plt.ylabel('score')\n",
    "plt.xlabel('number of trees')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(range_m, scores_m)\n",
    "plt.ylabel('score')\n",
    "plt.xlabel('max depth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest classifier is remarkably easy to implement, but yet very powerful. Once the best features and parameters are chosen, the classifier can be fit on the entire training set. Then, the submission set is fed through the trees and the random forest classifier makes a probabilistic predition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=500, max_depth=20)\n",
    "rfc.fit(train_x, train_y)\n",
    "pred = rfc.predict_proba(submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle gives a sample submission file, so it is easiest to just read that into a DataFrame and modify the `shot_made_flag` with predictions from the random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"sample_submission.csv\")\n",
    "sub['shot_made_flag'] = pred[:,1]\n",
    "sub.to_csv(\"real_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
